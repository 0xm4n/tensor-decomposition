{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import csv\n",
    "from os import listdir\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.mllib.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Step 1 - Set up the Spark\n",
    "'''\n",
    "conf = pyspark.SparkConf()\\\n",
    "        .setAppName('appName')\\\n",
    "        .set('spark.executor.memory', '80G')\\\n",
    "        .set('spark.driver.memory', '80G')\\\n",
    "        .set('spark.driver.maxResultSize', '80G')\\\n",
    "        .setMaster('local[*]')\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)\n",
    "#sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_vertex_id</th>\n",
       "      <th>e_vertex_id</th>\n",
       "      <th>time</th>\n",
       "      <th>freq</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203492</td>\n",
       "      <td>217680</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217680</td>\n",
       "      <td>217681</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>217681</td>\n",
       "      <td>217682</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>217682</td>\n",
       "      <td>196445</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196445</td>\n",
       "      <td>196446</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   s_vertex_id  e_vertex_id  time  freq  user_id\n",
       "0       203492       217680     0     1        1\n",
       "1       217680       217681     0     1        1\n",
       "2       217681       217682     0     1        1\n",
       "3       217682       196445     0     1        1\n",
       "4       196445       196446     0     1        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Step 2 - Combine all users into one df & give each user a user_id\n",
    "'''\n",
    "\n",
    "# Get all text files in data folder\n",
    "files = []\n",
    "for file in glob.glob(\"data/*.txt\"):\n",
    "    files.append(file)\n",
    "    \n",
    "# Put all the files into one dataframe and give each user an ID\n",
    "users_dict = []\n",
    "df = pd.DataFrame()\n",
    "for idx,file in enumerate(files): \n",
    "    file_name = file[6:12]\n",
    "    file_dict = [file_name,idx+1]\n",
    "    users_dict.append(file_dict)\n",
    "    df_file = pd.read_csv(file, sep = '\\t', header=None)\n",
    "    df_file[\"user_id\"] = idx + 1\n",
    "    df = df.append(df_file, ignore_index=True)\n",
    "df.columns = ['s_vertex_id','e_vertex_id', 'time', 'freq', 'user_id']\n",
    "\n",
    "# Save the users_dict\n",
    "with open('users_dict.csv', 'w', newline='') as resultFile:\n",
    "    wr = csv.writer(resultFile, dialect='excel')\n",
    "    wr.writerows(users_dict)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_vertex_id</th>\n",
       "      <th>e_vertex_id</th>\n",
       "      <th>time</th>\n",
       "      <th>freq</th>\n",
       "      <th>user_id</th>\n",
       "      <th>behavior_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203492</td>\n",
       "      <td>217680</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203492</td>\n",
       "      <td>217680</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>203492</td>\n",
       "      <td>217680</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203492</td>\n",
       "      <td>217680</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>217680</td>\n",
       "      <td>217681</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   s_vertex_id  e_vertex_id  time  freq  user_id  behavior_id\n",
       "0       203492       217680     0     1        1            1\n",
       "1       203492       217680     0     1       23            1\n",
       "2       203492       217680     0     1       24            1\n",
       "3       203492       217680     0     1       25            1\n",
       "4       217680       217681     0     1        1            2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Step 3 - Set a behavior_id for each ['s_vertex_id','e_vertex_id',time] pair\n",
    "'''\n",
    "\n",
    "behavior_dict = df.copy()\n",
    "behavior_dict.drop(['freq', 'user_id'], axis=1, inplace=True)\n",
    "behavior_dict.drop_duplicates(subset=['s_vertex_id', 'e_vertex_id', 'time'], keep=\"first\", inplace=True)\n",
    "behavior_dict.reset_index(drop = True, inplace = True)\n",
    "\n",
    "indices = list(range(1, len(behavior_dict) + 1))\n",
    "behavior_dict['behavior_id'] = indices\n",
    "\n",
    "behavior_dict_w  = behavior_dict.copy()\n",
    "behavior_dict_w = behavior_dict_w.values.tolist()\n",
    "behavior_dict_w = list(map(lambda tokens: tokens[:4], behavior_dict_w))\n",
    "\n",
    "# Save the behavior dict\n",
    "with open('behavior_dict.csv', 'w', newline='') as resultFile:\n",
    "    wr = csv.writer(resultFile, dialect='excel')\n",
    "    wr.writerows(behavior_dict_w)\n",
    "\n",
    "# Join the item_dict with the dataframe\n",
    "df = pd.merge(df, behavior_dict, on=['s_vertex_id', 'e_vertex_id','time'], how='inner')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (2, 1), (3, 1), (4, 1), (5, 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Step 4 - Create the prediction RDD\n",
    "\n",
    "'''\n",
    "\n",
    "num_users = len(files)\n",
    "num_behaviors = len(behavior_dict)\n",
    "\n",
    "users_id = list(range(1, num_users+1))\n",
    "behaviors_RDD = sc.range(1, num_behaviors+1)\n",
    "\n",
    "\n",
    "prediction_RDD = behaviors_RDD.flatMap(lambda b: map(lambda u: (u,b), users_id) )\n",
    "prediction_RDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1, 1), (6, 1, 1), (16, 1, 1), (18, 1, 1), (24, 1, 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Step 5 - Create the training RDD\n",
    "'''\n",
    "\n",
    "df = df.drop(['segment_id', 'time'], axis = 1)\n",
    "df.dropna()\n",
    "df = df[['user_id', 'behavior_id', 'freq']]\n",
    "df = df.values.tolist()\n",
    "df = list(map(lambda tokens: tuple(tokens), df))\n",
    "training_RDD = sc.parallelize(df)\n",
    "training_RDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 6 - Set the params for training\n",
    "'''\n",
    "seed = 5\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [15, 20, 25, 30]\n",
    "errors = []\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "nonnegative = True\n",
    "# alpha â€“ A constant used in computing confidence. (default: 0.01)\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 15 | RMSE 0.845529\n",
      "Rank 20 | RMSE 0.763278\n",
      "Rank 25 | RMSE 0.678170\n",
      "Rank 30 | RMSE 0.603680\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step 7 - Using ALS to train a model\n",
    "'''\n",
    "for idx,rank in enumerate(ranks):\n",
    "    model = ALS.trainImplicit(training_RDD, rank=rank, seed=seed, iterations=iterations, lambda_=regularization_parameter, nonnegative=nonnegative, alpha=alpha)\n",
    "    predictions = model.predictAll(prediction_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = training_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    errors.append(error)\n",
    "\n",
    "for i in range(len(ranks)):\n",
    "    print('Rank %d | RMSE %f' %(ranks[i], errors[i]))\n",
    "    \n",
    "if len(ranks) > 1:\n",
    "    # Get best rank\n",
    "    best_rank = ranks[errors.index(min(errors))]\n",
    "    model = ALS.trainImplicit(training_RDD, rank=best_rank, seed=seed, iterations=iterations, lambda_=regularization_parameter, nonnegative=nonnegative, alpha=alpha)\n",
    "    predictions = model.predictAll(prediction_RDD).map(lambda r: ((r[0], r[1]), r[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 8 - Save the prediction\n",
    "'''\n",
    "predictions = predictions.sortByKey().map(lambda x: (x[0][0], x[0][1], x[1]))\n",
    "predictions.coalesce(1).saveAsTextFile(\"predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
